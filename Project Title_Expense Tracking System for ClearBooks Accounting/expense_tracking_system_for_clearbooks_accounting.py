# -*- coding: utf-8 -*-
"""Expense Tracking System for ClearBooks Accounting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CgYMb_WAMF1APdEFAtEzP71Rosa9uFzz
"""

# ðŸ“˜ Expense Tracking System for ClearBooks Accounting
print('Hello from YBI Foundation ðŸš€')

# ðŸ“¦ Section 1: Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
import warnings
warnings.filterwarnings("ignore")

# ðŸ“‚ Section 2: Load Dataset
summary_df = pd.read_csv('/content/Expense_Summary_By_Category.csv')
records_df = pd.read_csv('/content/Expense_Records_ClearBooks.csv')
print("âœ… Summary Shape:", summary_df.shape)
print("âœ… Records Shape:", records_df.shape)

from google.colab import drive
drive.mount('/content/drive')

# ðŸ§¹ Section 3: Preprocessing
df = records_df.copy()
print("ðŸ§¼ Null values:
", df.isnull().sum())
df = df.dropna(subset=['Description', 'Category'])
df[['Description', 'Category']].head()

# ðŸ“Š Section 4: Exploratory Data Analysis
plt.figure(figsize=(10,5))
sns.countplot(y='Category', data=df, order=df['Category'].value_counts().index)
plt.title("Expense Count by Category")
plt.show()

text = " ".join(df['Description'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)
plt.figure(figsize=(10,5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title("WordCloud of Expense Descriptions")
plt.show()

# ðŸ”¢ Section 5: Feature Engineering
tfidf = TfidfVectorizer(max_features=3000)
X = tfidf.fit_transform(df['Description'])
y = df['Category']
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_encoded = le.fit_transform(y)
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# ðŸ¤– Section 6: Model Training
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# ðŸ“ˆ Section 7: Evaluation
y_pred = model.predict(X_test)
print("ðŸ“‹ Classification Report:
", classification_report(y_test, y_pred, target_names=le.classes_))
plt.figure(figsize=(10,6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d',
            xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')
plt.title("Confusion Matrix")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

# ðŸ”® Section 8: Prediction on New Data
sample_text = ["Hotel bill at Taj", "Monthly Amazon Prime subscription", "Client dinner at Barbeque Nation"]
sample_features = tfidf.transform(sample_text)
sample_pred = le.inverse_transform(model.predict(sample_features))
for text, pred in zip(sample_text, sample_pred):
    print(f'"{text}" âž¤ Predicted Category: {pred}')